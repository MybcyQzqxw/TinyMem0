#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
åµŒå…¥æ¨¡å‹ä¸‹è½½è„šæœ¬
æä¾›äº¤äº’å¼å’Œå‘½ä»¤è¡Œä¸¤ç§æ–¹å¼ä¸‹è½½åµŒå…¥æ¨¡å‹
"""

import os
import sys
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.model_manager import download_embedding_model


# é¢„å®šä¹‰çš„å¸¸ç”¨æ¨¡å‹åˆ—è¡¨
AVAILABLE_MODELS = {
    '1': {
        'id': 'AI-ModelScope/bge-small-zh-v1.5',
        'name': 'BGE-Small-ZH v1.5',
        'size': '~400MB',
        'dims': 512,
        'lang': 'ä¸­æ–‡ä¼˜åŒ–',
        'description': 'æ¨èï¼šä¸­æ–‡æ£€ç´¢æ•ˆæœå¥½ï¼Œä½“ç§¯å°'
    },
    '2': {
        'id': 'AI-ModelScope/bge-base-zh-v1.5',
        'name': 'BGE-Base-ZH v1.5',
        'size': '~800MB',
        'dims': 768,
        'lang': 'ä¸­æ–‡ä¼˜åŒ–',
        'description': 'æ›´å¥½çš„æ•ˆæœï¼Œä½“ç§¯é€‚ä¸­'
    },
    '3': {
        'id': 'AI-ModelScope/bge-large-zh-v1.5',
        'name': 'BGE-Large-ZH v1.5',
        'size': '~1.5GB',
        'dims': 1024,
        'lang': 'ä¸­æ–‡ä¼˜åŒ–',
        'description': 'æœ€ä½³æ•ˆæœï¼Œä½“ç§¯è¾ƒå¤§'
    },
    '4': {
        'id': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',
        'name': 'Multilingual MiniLM',
        'size': '~450MB',
        'dims': 384,
        'lang': 'å¤šè¯­è¨€',
        'description': 'æ”¯æŒ50+ç§è¯­è¨€'
    },
    '5': {
        'id': 'sentence-transformers/all-MiniLM-L6-v2',
        'name': 'All-MiniLM-L6-v2',
        'size': '~90MB',
        'dims': 384,
        'lang': 'è‹±æ–‡ä¼˜åŒ–',
        'description': 'æœ€å°ä½“ç§¯ï¼Œè‹±æ–‡ä»»åŠ¡'
    }
}


def print_banner():
    """æ‰“å°æ¬¢è¿æ¨ªå¹…"""
    print("=" * 60)
    print("ğŸš€ TinyMem0 åµŒå…¥æ¨¡å‹ä¸‹è½½å·¥å…·")
    print("=" * 60)
    print()


def print_models():
    """æ‰“å°å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
    print("ğŸ“‹ å¯ç”¨çš„åµŒå…¥æ¨¡å‹ï¼š\n")
    for key, model in AVAILABLE_MODELS.items():
        print(f"[{key}] {model['name']}")
        print(f"    æ¨¡å‹ID: {model['id']}")
        print(f"    å¤§å°: {model['size']} | ç»´åº¦: {model['dims']} | è¯­è¨€: {model['lang']}")
        print(f"    è¯´æ˜: {model['description']}")
        print()


def interactive_download():
    """äº¤äº’å¼ä¸‹è½½æ¨¡å¼"""
    print_banner()
    print_models()
    
    while True:
        choice = input("è¯·é€‰æ‹©è¦ä¸‹è½½çš„æ¨¡å‹ [1-5] (è¾“å…¥ 'q' é€€å‡º): ").strip()
        
        if choice.lower() == 'q':
            print("ğŸ‘‹ é€€å‡ºä¸‹è½½")
            return
        
        if choice not in AVAILABLE_MODELS:
            print("âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥\n")
            continue
        
        model = AVAILABLE_MODELS[choice]
        print(f"\nâœ… ä½ é€‰æ‹©äº†: {model['name']}")
        print(f"ğŸ“¦ æ¨¡å‹ID: {model['id']}")
        print(f"ğŸ’¾ å¤§å°: {model['size']}")
        
        # è¯¢é—®ä¸‹è½½ç›®å½•
        default_cache = './embedding_models'
        cache_dir = input(f"\nğŸ“ ä¸‹è½½ç›®å½• [é»˜è®¤: {default_cache}]: ").strip()
        if not cache_dir:
            cache_dir = default_cache
        
        # ç¡®è®¤ä¸‹è½½
        confirm = input(f"\nç¡®è®¤ä¸‹è½½åˆ° {cache_dir}? [Y/n]: ").strip().lower()
        if confirm in ['', 'y', 'yes']:
            try:
                print(f"\nâ³ å¼€å§‹ä¸‹è½½ {model['name']}...")
                downloaded_path = download_embedding_model(
                    model_id=model['id'],
                    cache_dir=cache_dir
                )
                
                print(f"\nâœ… ä¸‹è½½æˆåŠŸï¼")
                print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {downloaded_path}")
                print(f"\nğŸ“ è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®:")
                print(f"   LOCAL_EMBEDDING_MODEL={downloaded_path}")
                print(f"   EMBEDDING_DIM={model['dims']}")
                
                # è¯¢é—®æ˜¯å¦ç»§ç»­ä¸‹è½½
                cont = input("\næ˜¯å¦ç»§ç»­ä¸‹è½½å…¶ä»–æ¨¡å‹? [y/N]: ").strip().lower()
                if cont not in ['y', 'yes']:
                    print("ğŸ‘‹ å®Œæˆä¸‹è½½")
                    return
                else:
                    print()
                    print_models()
                    
            except Exception as e:
                print(f"\nâŒ ä¸‹è½½å¤±è´¥: {e}")
                cont = input("\næ˜¯å¦é‡è¯•æˆ–é€‰æ‹©å…¶ä»–æ¨¡å‹? [y/N]: ").strip().lower()
                if cont not in ['y', 'yes']:
                    return
                else:
                    print()
                    print_models()
        else:
            print("âŒ å–æ¶ˆä¸‹è½½\n")


def command_line_download(args):
    """å‘½ä»¤è¡Œä¸‹è½½æ¨¡å¼"""
    print_banner()
    
    model_id = args.model_id
    cache_dir = args.cache_dir
    
    # å¦‚æœæ˜¯æ•°å­—ï¼Œä»é¢„å®šä¹‰åˆ—è¡¨ä¸­è·å–
    if model_id in AVAILABLE_MODELS:
        model = AVAILABLE_MODELS[model_id]
        model_id = model['id']
        print(f"ğŸ“¦ ä½¿ç”¨é¢„å®šä¹‰æ¨¡å‹: {model['name']}")
        print(f"ğŸ”— æ¨¡å‹ID: {model_id}")
    else:
        print(f"ğŸ“¦ è‡ªå®šä¹‰æ¨¡å‹ID: {model_id}")
    
    print(f"ğŸ“ ä¸‹è½½ç›®å½•: {cache_dir}")
    
    try:
        print(f"\nâ³ å¼€å§‹ä¸‹è½½...")
        downloaded_path = download_embedding_model(
            model_id=model_id,
            cache_dir=cache_dir
        )
        
        print(f"\nâœ… ä¸‹è½½æˆåŠŸï¼")
        print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {downloaded_path}")
        
        # å¦‚æœæ˜¯é¢„å®šä¹‰æ¨¡å‹ï¼Œæ˜¾ç¤ºé…ç½®å»ºè®®
        if args.model_id in AVAILABLE_MODELS:
            model = AVAILABLE_MODELS[args.model_id]
            print(f"\nğŸ“ å»ºè®®é…ç½® (.env æ–‡ä»¶):")
            print(f"   LOCAL_EMBEDDING_MODEL={downloaded_path}")
            print(f"   EMBEDDING_DIM={model['dims']}")
        else:
            print(f"\nğŸ“ è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®:")
            print(f"   LOCAL_EMBEDDING_MODEL={downloaded_path}")
        
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½å¤±è´¥: {e}")
        sys.exit(1)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='TinyMem0 åµŒå…¥æ¨¡å‹ä¸‹è½½å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # äº¤äº’å¼æ¨¡å¼ï¼ˆæ¨èï¼‰
  python scripts/download_embedding.py
  
  # ä¸‹è½½é¢„å®šä¹‰æ¨¡å‹
  python scripts/download_embedding.py --model-id 1
  
  # ä¸‹è½½è‡ªå®šä¹‰æ¨¡å‹
  python scripts/download_embedding.py --model-id AI-ModelScope/bge-small-zh-v1.5
  
  # æŒ‡å®šä¸‹è½½ç›®å½•
  python scripts/download_embedding.py --model-id 1 --cache-dir ./models
        """
    )
    
    parser.add_argument(
        '--model-id',
        type=str,
        help='æ¨¡å‹ID (1-5ä½¿ç”¨é¢„å®šä¹‰æ¨¡å‹ï¼Œæˆ–æŒ‡å®šå®Œæ•´æ¨¡å‹ID)'
    )
    
    parser.add_argument(
        '--cache-dir',
        type=str,
        default='./embedding_models',
        help='æ¨¡å‹ä¸‹è½½ç›®å½• (é»˜è®¤: ./embedding_models)'
    )
    
    parser.add_argument(
        '--list',
        action='store_true',
        help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„é¢„å®šä¹‰æ¨¡å‹'
    )
    
    args = parser.parse_args()
    
    # å¦‚æœåªæ˜¯åˆ—å‡ºæ¨¡å‹
    if args.list:
        print_banner()
        print_models()
        return
    
    # å¦‚æœæŒ‡å®šäº†model-idï¼Œä½¿ç”¨å‘½ä»¤è¡Œæ¨¡å¼
    if args.model_id:
        command_line_download(args)
    else:
        # å¦åˆ™ä½¿ç”¨äº¤äº’å¼æ¨¡å¼
        interactive_download()


if __name__ == "__main__":
    main()
